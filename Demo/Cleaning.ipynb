{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from the provided file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first few rows to inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Time                  Police Station       City  \\\n",
      "0 2023-12-26  18:12:15     Nungambakkam Police Station      Patna   \n",
      "1 2023-03-01  15:03:00  Connaught Place Police Station    Kolkata   \n",
      "2 2023-12-03  01:25:20     Nungambakkam Police Station  Bengaluru   \n",
      "3 2023-09-21  21:00:24       Cantonment Police Station      Patna   \n",
      "4 2023-08-24  18:24:50     Lajpat Nagar Police Station    Chennai   \n",
      "\n",
      "         State   Crime Type Fir Number  \n",
      "0        Bihar  Cyber Crime  FIR000001  \n",
      "1  West Bengal        Theft  FIR000002  \n",
      "2    Karnataka       Murder  FIR000003  \n",
      "3        Bihar   Kidnapping  FIR000004  \n",
      "4   Tamil Nadu   Kidnapping  FIR000005  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Date            10000 non-null  datetime64[ns]\n",
      " 1   Time            10000 non-null  object        \n",
      " 2   Police Station  10000 non-null  object        \n",
      " 3   City            10000 non-null  object        \n",
      " 4   State           10000 non-null  object        \n",
      " 5   Crime Type      10000 non-null  object        \n",
      " 6   Fir Number      10000 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 547.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Date\n",
      "count                       10000\n",
      "mean   2022-09-09 22:10:59.520000\n",
      "min           2020-09-15 00:00:00\n",
      "25%           2021-09-10 00:00:00\n",
      "50%           2022-09-08 00:00:00\n",
      "75%           2023-09-07 00:00:00\n",
      "max           2024-09-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Time              0\n",
      "Police Station    0\n",
      "City              0\n",
      "State             0\n",
      "Crime Type        0\n",
      "Fir Number        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data\n",
    "\n",
    "Removing Rows with Null Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Time              0\n",
      "Police Station    0\n",
      "City              0\n",
      "State             0\n",
      "Crime Type        0\n",
      "Fir Number        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Verify that null values have been removed\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Columns with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Time              0\n",
      "Police Station    0\n",
      "City              0\n",
      "State             0\n",
      "Crime Type        0\n",
      "Fir Number        0\n",
      "dtype: int64\n",
      "Original shape: (10000, 7)\n",
      "New shape after removing columns with null values: (10000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with any missing (null) values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "# Verify that columns with null values have been removed\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Display the shape of the new dataset (rows, columns) after column removal\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"New shape after removing columns with null values: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save df_cleaned as processed_data in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('processed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
